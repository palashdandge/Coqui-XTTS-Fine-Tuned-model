{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palashdandge/Coqui-XTTS-Fine-Tuned-model/blob/main/Coqui_XTTS_My_FIned_Tuned_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th91ofnQWr8Y"
      },
      "source": [
        "## Dataset building + XTTS finetuning and inference\n",
        "\n",
        "#### Running the demo\n",
        "To start the demo run the first two cells (ignore pip install errors in the first one)\n",
        "\n",
        "Then click on the link `Running on public URL: ` when the demo is ready.\n",
        "\n",
        "#### Downloading the results\n",
        "\n",
        "You can run cell [3] to zip and download default dataset path\n",
        "\n",
        "You can run cell [4] to zip and download the latest model you trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdWKA_xFqkKq"
      },
      "source": [
        "### Installing the requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmUUQqdN6BXk",
        "outputId": "7a2a7d20-c607-4681-ec61-0f32113b26fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m833.7/833.7 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building editable for TTS (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's legacy dependency resolver does not consider dependency conflicts when selecting packages. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.13 requires numpy<2,>=1.24.4, but you'll have numpy 1.22.0 which is incompatible.\n",
            "albumentations 1.4.14 requires numpy>=1.24.4, but you'll have numpy 1.22.0 which is incompatible.\n",
            "arviz 0.18.0 requires numpy<2.0,>=1.23.0, but you'll have numpy 1.22.0 which is incompatible.\n",
            "astropy 6.1.2 requires numpy>=1.23, but you'll have numpy 1.22.0 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you'll have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you'll have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you'll have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you'll have pandas 1.5.3 which is incompatible.\n",
            "librosa 0.10.2.post1 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you'll have numpy 1.22.0 which is incompatible.\n",
            "numexpr 2.10.1 requires numpy>=1.23.0, but you'll have numpy 1.22.0 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you'll have numpy 1.22.0 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you'll have numpy 1.22.0 which is incompatible.\n",
            "rmm-cu12 24.4.0 requires numpy<2.0a0,>=1.23, but you'll have numpy 1.22.0 which is incompatible.\n",
            "scikit-image 0.23.2 requires numpy>=1.23, but you'll have numpy 1.22.0 which is incompatible.\n",
            "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you'll have numpy 1.22.0 which is incompatible.\n",
            "statsmodels 0.14.2 requires numpy>=1.22.3, but you'll have numpy 1.22.0 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you'll have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.6.0 requires numpy>=1.23, but you'll have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.6.0 requires pandas>=2.0, but you'll have pandas 1.5.3 which is incompatible.\n",
            "gruut 2.2.3 requires networkx<3.0.0,>=2.5.0, but you'll have networkx 3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.8/36.8 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33m  WARNING: typer 0.12.4 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's legacy dependency resolver does not consider dependency conflicts when selecting packages. This behaviour is the source of the following dependency conflicts.\n",
            "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you'll have huggingface-hub 0.23.5 which is incompatible.\n",
            "transformers 4.42.4 requires tokenizers<0.20,>=0.19, but you'll have tokenizers 0.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tts 0.20.6 requires numpy==1.22.0; python_version <= \"3.10\", but you have numpy 1.26.2 which is incompatible.\n",
            "albucore 0.0.13 requires typing-extensions>=4.9.0, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "albumentations 1.4.14 requires typing-extensions>=4.9.0, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "gruut 2.2.3 requires networkx<3.0.0,>=2.5.0, but you have networkx 3.3 which is incompatible.\n",
            "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.23.5 which is incompatible.\n",
            "transformers 4.42.4 requires tokenizers<0.20,>=0.19, but you have tokenizers 0.14.1 which is incompatible.\n",
            "typeguard 4.3.0 requires typing-extensions>=4.10.0, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "xarray 2024.6.0 requires pandas>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!rm -rf TTS/ # delete repo to be able to reinstall if needed\n",
        "!git clone --branch xtts_demo -q https://github.com/coqui-ai/TTS.git\n",
        "!pip install --use-deprecated=legacy-resolver -q -e TTS\n",
        "!pip install --use-deprecated=legacy-resolver -q -r TTS/TTS/demos/xtts_ft_demo/requirements.txt\n",
        "!pip install -q typing_extensions==4.8 numpy==1.26.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyTorch with CUDA support\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install missing CUDA libraries\n",
        "!apt-get update\n",
        "!apt-get install -y libcusolver11 libcusparse11 libcublas11\n",
        "!apt-get update\n",
        "!apt-get install -y --no-install-recommends libcublas-11-0 libcusolver11 libcusparse11 libcudnn8\n",
        "!ldconfig -p | grep libcublas\n"
      ],
      "metadata": {
        "id": "OpmfZ7hnxiTG",
        "outputId": "249ed9d8-7cd0-43e4-ad88-94297cc89420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [945 kB]\n",
            "Ign:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,425 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,234 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,498 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [81.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.7 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Hit:18 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:19 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [53.3 kB]\n",
            "Get:20 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,556 kB]\n",
            "Fetched 16.2 MB in 5s (3,586 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libcublaslt11\n",
            "The following NEW packages will be installed:\n",
            "  libcublas11 libcublaslt11 libcusolver11 libcusparse11\n",
            "0 upgraded, 4 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 354 MB of archives.\n",
            "After this operation, 967 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcublaslt11 amd64 11.7.4.6~11.5.1-1ubuntu1 [148 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcublas11 amd64 11.7.4.6~11.5.1-1ubuntu1 [78.2 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcusolver11 amd64 11.3.2.107~11.5.1-1ubuntu1 [31.3 MB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 libcusparse11 amd64 11.7.0.107~11.5.1-1ubuntu1 [96.2 MB]\n",
            "Fetched 354 MB in 29s (12.3 MB/s)\n",
            "Selecting previously unselected package libcublaslt11:amd64.\n",
            "(Reading database ... 123595 files and directories currently installed.)\n",
            "Preparing to unpack .../libcublaslt11_11.7.4.6~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcublaslt11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcublas11:amd64.\n",
            "Preparing to unpack .../libcublas11_11.7.4.6~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcublas11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcusolver11:amd64.\n",
            "Preparing to unpack .../libcusolver11_11.3.2.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcusolver11:amd64 (11.3.2.107~11.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libcusparse11:amd64.\n",
            "Preparing to unpack .../libcusparse11_11.7.0.107~11.5.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libcusparse11:amd64 (11.7.0.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libcusparse11:amd64 (11.7.0.107~11.5.1-1ubuntu1) ...\n",
            "Setting up libcublaslt11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Setting up libcublas11:amd64 (11.7.4.6~11.5.1-1ubuntu1) ...\n",
            "Setting up libcusolver11:amd64 (11.3.2.107~11.5.1-1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Ign:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Package libcublas-11-0 is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "\n",
            "E: Package 'libcublas-11-0' has no installation candidate\n",
            "\tlibcublasLt.so.12 (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libcublasLt.so.12\n",
            "\tlibcublasLt.so.11 (libc6,x86-64) => /lib/x86_64-linux-gnu/libcublasLt.so.11\n",
            "\tlibcublasLt.so (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libcublasLt.so\n",
            "\tlibcublas.so.12 (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libcublas.so.12\n",
            "\tlibcublas.so.11 (libc6,x86-64) => /lib/x86_64-linux-gnu/libcublas.so.11\n",
            "\tlibcublas.so (libc6,x86-64) => /usr/local/cuda/targets/x86_64-linux/lib/libcublas.so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7rNt1e2qtDP"
      },
      "source": [
        "### Running the gradio UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zd2xo_7a8wyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc70fc8b-0cc7-4ac6-82ed-958630b082d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
            "  Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.14.1\n",
            "    Uninstalling tokenizers-0.14.1:\n",
            "      Successfully uninstalled tokenizers-0.14.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tts 0.20.6 requires numpy==1.22.0; python_version <= \"3.10\", but you have numpy 1.26.2 which is incompatible.\n",
            "faster-whisper 0.9.0 requires tokenizers<0.15,>=0.13, but you have tokenizers 0.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.19.1 transformers-4.44.2\n",
            "Running on local URL:  http://0.0.0.0:5003\n",
            "IMPORTANT: You are using gradio version 4.7.1, however version 4.29.0 is available, please upgrade.\n",
            "--------\n",
            "Running on public URL: https://1512a9b05dadae2db3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Loading Whisper Model!\n",
            "2024-08-26 03:51:22,882 [INFO] Processing audio with duration 00:20.309\n",
            "2024-08-26 03:51:28,481 [INFO] Processing audio with duration 00:21.035\n",
            "2024-08-26 03:51:30,658 [INFO] Processing audio with duration 00:18.432\n",
            "2024-08-26 03:51:32,459 [INFO] Processing audio with duration 00:21.355\n",
            "The sum of the duration of the audios that you provided should be at least 2 minutes!\n",
            "Loading Whisper Model!\n",
            "2024-08-26 04:39:19,059 [INFO] Processing audio with duration 00:20.309\n",
            "2024-08-26 04:39:21,347 [INFO] Processing audio with duration 00:21.035\n",
            "2024-08-26 04:39:23,844 [INFO] Processing audio with duration 00:18.432\n",
            "2024-08-26 04:39:26,044 [INFO] Processing audio with duration 00:21.355\n",
            "2024-08-26 04:39:28,414 [INFO] Processing audio with duration 00:53.120\n",
            "2024-08-26 04:39:34,032 [INFO] Processing audio with duration 00:52.288\n",
            "Dataset Processed!\n",
            " > Downloading DVAE files!\n",
            "  0%|          | 0.00/1.07k [00:00<?, ?iB/s]\n",
            "100%|##########| 1.07k/1.07k [00:00<00:00, 1.49kiB/s]\n",
            "\n",
            "  3%|3         | 7.19M/211M [00:00<00:02, 71.6MiB/s]\u001b[A\n",
            "  8%|7         | 16.1M/211M [00:00<00:02, 81.7MiB/s]\u001b[A\n",
            " 12%|#1        | 24.2M/211M [00:00<00:02, 72.5MiB/s]\u001b[A\n",
            " 15%|#5        | 31.6M/211M [00:00<00:03, 51.8MiB/s]\u001b[A\n",
            " 19%|#8        | 39.8M/211M [00:00<00:02, 59.9MiB/s]\u001b[A\n",
            " 23%|##3       | 48.4M/211M [00:00<00:02, 67.4MiB/s]\u001b[A\n",
            " 27%|##7       | 57.4M/211M [00:00<00:02, 73.8MiB/s]\u001b[A\n",
            " 32%|###1      | 66.5M/211M [00:00<00:01, 78.7MiB/s]\u001b[A\n",
            " 36%|###5      | 75.7M/211M [00:01<00:01, 82.5MiB/s]\u001b[A\n",
            " 40%|####      | 84.5M/211M [00:01<00:01, 84.3MiB/s]\u001b[A\n",
            " 44%|####4     | 93.2M/211M [00:01<00:01, 81.1MiB/s]\u001b[A\n",
            " 48%|####8     | 101M/211M [00:01<00:01, 75.1MiB/s] \u001b[A\n",
            " 52%|#####2    | 110M/211M [00:01<00:01, 76.8MiB/s]\u001b[A\n",
            " 56%|#####6    | 118M/211M [00:01<00:01, 78.9MiB/s]\u001b[A\n",
            " 60%|#####9    | 126M/211M [00:01<00:01, 77.1MiB/s]\u001b[A\n",
            " 64%|######3   | 134M/211M [00:01<00:00, 77.6MiB/s]\u001b[A\n",
            " 67%|######7   | 142M/211M [00:01<00:00, 78.7MiB/s]\u001b[A\n",
            " 72%|#######1  | 151M/211M [00:01<00:00, 81.2MiB/s]\u001b[A\n",
            " 76%|#######5  | 160M/211M [00:02<00:00, 83.4MiB/s]\u001b[A\n",
            " 80%|########  | 169M/211M [00:02<00:00, 86.5MiB/s]\u001b[A\n",
            " 85%|########4 | 178M/211M [00:02<00:00, 87.3MiB/s]\u001b[A\n",
            " 89%|########8 | 187M/211M [00:02<00:00, 86.2MiB/s]\u001b[A\n",
            " 93%|#########2| 196M/211M [00:02<00:00, 87.4MiB/s]\u001b[A\n",
            "100%|##########| 211M/211M [00:02<00:00, 78.6MiB/s]\n",
            " > Downloading XTTS v2.0 files!\n",
            " 32%|###2      | 116k/361k [00:00<00:00, 473kiB/s]\n",
            "100%|##########| 361k/361k [00:00<00:00, 452kiB/s]\n",
            "\n",
            "  0%|          | 7.33M/1.87G [00:00<00:25, 73.3MiB/s]\u001b[A\n",
            "  1%|          | 15.7M/1.87G [00:00<00:23, 79.4MiB/s]\u001b[A\n",
            "  1%|1         | 23.7M/1.87G [00:00<00:23, 79.5MiB/s]\u001b[A\n",
            "  2%|1         | 32.4M/1.87G [00:00<00:22, 82.8MiB/s]\u001b[A\n",
            "  2%|2         | 40.8M/1.87G [00:00<00:21, 83.2MiB/s]\u001b[A\n",
            "  3%|2         | 49.3M/1.87G [00:00<00:21, 83.8MiB/s]\u001b[A\n",
            "  3%|3         | 57.7M/1.87G [00:00<00:21, 83.9MiB/s]\u001b[A\n",
            "  4%|3         | 66.9M/1.87G [00:00<00:20, 86.4MiB/s]\u001b[A\n",
            "  4%|4         | 75.6M/1.87G [00:00<00:20, 86.6MiB/s]\u001b[A\n",
            "  5%|4         | 84.3M/1.87G [00:01<00:21, 84.0MiB/s]\u001b[A\n",
            "  5%|4         | 92.7M/1.87G [00:01<00:22, 80.6MiB/s]\u001b[A\n",
            "  5%|5         | 101M/1.87G [00:01<00:23, 74.4MiB/s] \u001b[A\n",
            "  6%|5         | 109M/1.87G [00:01<00:22, 77.0MiB/s]\u001b[A\n",
            "  6%|6         | 117M/1.87G [00:01<00:22, 77.7MiB/s]\u001b[A\n",
            "  7%|6         | 125M/1.87G [00:01<00:22, 77.8MiB/s]\u001b[A\n",
            "  7%|7         | 133M/1.87G [00:01<00:22, 77.2MiB/s]\u001b[A\n",
            "  8%|7         | 141M/1.87G [00:01<00:22, 75.7MiB/s]\u001b[A\n",
            "  8%|7         | 148M/1.87G [00:01<00:22, 76.6MiB/s]\u001b[A\n",
            "  8%|8         | 156M/1.87G [00:01<00:22, 77.5MiB/s]\u001b[A\n",
            "  9%|8         | 164M/1.87G [00:02<00:22, 75.3MiB/s]\u001b[A\n",
            "  9%|9         | 172M/1.87G [00:02<00:22, 76.3MiB/s]\u001b[A\n",
            " 10%|9         | 181M/1.87G [00:02<00:21, 79.0MiB/s]\u001b[A\n",
            " 10%|#         | 189M/1.87G [00:02<00:20, 81.0MiB/s]\u001b[A\n",
            " 11%|#         | 198M/1.87G [00:02<00:20, 82.8MiB/s]\u001b[A\n",
            " 11%|#1        | 206M/1.87G [00:02<00:22, 75.0MiB/s]\u001b[A\n",
            " 11%|#1        | 214M/1.87G [00:02<00:21, 76.2MiB/s]\u001b[A\n",
            " 12%|#1        | 222M/1.87G [00:02<00:21, 78.2MiB/s]\u001b[A\n",
            " 12%|#2        | 230M/1.87G [00:02<00:20, 78.5MiB/s]\u001b[A\n",
            " 13%|#2        | 238M/1.87G [00:03<00:20, 79.3MiB/s]\u001b[A\n",
            " 13%|#3        | 246M/1.87G [00:03<00:20, 77.3MiB/s]\u001b[A\n",
            " 14%|#3        | 254M/1.87G [00:03<00:20, 77.3MiB/s]\u001b[A\n",
            " 14%|#4        | 263M/1.87G [00:03<00:20, 79.2MiB/s]\u001b[A\n",
            " 14%|#4        | 270M/1.87G [00:03<00:20, 79.1MiB/s]\u001b[A\n",
            " 15%|#4        | 278M/1.87G [00:03<00:20, 78.8MiB/s]\u001b[A\n",
            " 15%|#5        | 286M/1.87G [00:03<00:20, 78.2MiB/s]\u001b[A\n",
            " 16%|#5        | 294M/1.87G [00:03<00:19, 79.0MiB/s]\u001b[A\n",
            " 16%|#6        | 302M/1.87G [00:03<00:19, 78.3MiB/s]\u001b[A\n",
            " 17%|#6        | 311M/1.87G [00:03<00:19, 79.5MiB/s]\u001b[A\n",
            " 17%|#7        | 319M/1.87G [00:04<00:19, 81.1MiB/s]\u001b[A\n",
            " 18%|#7        | 327M/1.87G [00:04<00:19, 77.2MiB/s]\u001b[A\n",
            " 18%|#7        | 335M/1.87G [00:04<00:19, 78.2MiB/s]\u001b[A\n",
            " 18%|#8        | 343M/1.87G [00:06<02:28, 10.3MiB/s]\u001b[A\n",
            " 19%|#8        | 349M/1.87G [00:06<02:00, 12.6MiB/s]\u001b[A\n",
            " 19%|#8        | 354M/1.87G [00:06<01:38, 15.4MiB/s]\u001b[A\n",
            " 19%|#9        | 359M/1.87G [00:06<01:20, 18.8MiB/s]\u001b[A\n",
            " 20%|#9        | 365M/1.87G [00:07<01:06, 22.6MiB/s]\u001b[A\n",
            " 20%|#9        | 370M/1.87G [00:07<00:56, 26.5MiB/s]\u001b[A\n",
            " 20%|##        | 375M/1.87G [00:07<00:48, 30.8MiB/s]\u001b[A\n",
            " 20%|##        | 381M/1.87G [00:07<00:43, 34.5MiB/s]\u001b[A\n",
            " 21%|##        | 386M/1.87G [00:07<00:39, 37.5MiB/s]\u001b[A\n",
            " 21%|##        | 391M/1.87G [00:07<00:36, 40.2MiB/s]\u001b[A\n",
            " 21%|##1       | 396M/1.87G [00:07<00:36, 40.4MiB/s]\u001b[A\n",
            " 21%|##1       | 401M/1.87G [00:07<00:34, 42.5MiB/s]\u001b[A\n",
            " 22%|##1       | 406M/1.87G [00:07<00:32, 45.4MiB/s]\u001b[A\n",
            " 22%|##2       | 411M/1.87G [00:07<00:30, 47.8MiB/s]\u001b[A\n",
            " 22%|##2       | 416M/1.87G [00:08<00:29, 48.9MiB/s]\u001b[A\n",
            " 23%|##2       | 422M/1.87G [00:08<00:28, 50.5MiB/s]\u001b[A\n",
            " 23%|##2       | 427M/1.87G [00:08<00:29, 49.1MiB/s]\u001b[A\n",
            " 23%|##3       | 432M/1.87G [00:08<00:28, 49.7MiB/s]\u001b[A\n",
            " 23%|##3       | 437M/1.87G [00:08<00:30, 47.4MiB/s]\u001b[A\n",
            " 24%|##3       | 442M/1.87G [00:08<00:30, 46.5MiB/s]\u001b[A\n",
            " 24%|##3       | 447M/1.87G [00:08<00:29, 47.5MiB/s]\u001b[A\n",
            " 24%|##4       | 452M/1.87G [00:08<00:29, 48.4MiB/s]\u001b[A\n",
            " 24%|##4       | 457M/1.87G [00:08<00:30, 46.8MiB/s]\u001b[A\n",
            " 25%|##4       | 462M/1.87G [00:09<00:29, 47.5MiB/s]\u001b[A\n",
            " 25%|##4       | 467M/1.87G [00:09<00:29, 48.1MiB/s]\u001b[A\n",
            " 25%|##5       | 472M/1.87G [00:09<00:28, 48.5MiB/s]\u001b[A\n",
            " 26%|##5       | 477M/1.87G [00:09<00:28, 48.1MiB/s]\u001b[A\n",
            " 26%|##5       | 482M/1.87G [00:09<00:29, 47.4MiB/s]\u001b[A\n",
            " 26%|##6       | 486M/1.87G [00:09<00:30, 45.0MiB/s]\u001b[A\n",
            " 26%|##6       | 491M/1.87G [00:09<00:31, 43.7MiB/s]\u001b[A\n",
            " 27%|##6       | 495M/1.87G [00:09<00:31, 43.5MiB/s]\u001b[A\n",
            " 27%|##6       | 500M/1.87G [00:09<00:32, 42.2MiB/s]\u001b[A\n",
            " 27%|##7       | 505M/1.87G [00:09<00:30, 44.2MiB/s]\u001b[A\n",
            " 27%|##7       | 512M/1.87G [00:10<00:25, 52.9MiB/s]\u001b[A\n",
            " 28%|##7       | 521M/1.87G [00:10<00:21, 63.2MiB/s]\u001b[A\n",
            " 28%|##8       | 527M/1.87G [00:10<00:21, 63.8MiB/s]\u001b[A\n",
            " 29%|##8       | 534M/1.87G [00:10<00:20, 63.9MiB/s]\u001b[A\n",
            " 29%|##8       | 540M/1.87G [00:10<00:21, 62.6MiB/s]\u001b[A\n",
            " 29%|##9       | 547M/1.87G [00:10<00:20, 64.2MiB/s]\u001b[A\n",
            " 30%|##9       | 555M/1.87G [00:10<00:18, 69.1MiB/s]\u001b[A\n",
            " 30%|###       | 563M/1.87G [00:10<00:18, 71.0MiB/s]\u001b[A\n",
            " 31%|###       | 571M/1.87G [00:10<00:17, 75.7MiB/s]\u001b[A\n",
            " 31%|###       | 579M/1.87G [00:11<00:18, 69.9MiB/s]\u001b[A\n",
            " 31%|###1      | 586M/1.87G [00:11<00:18, 70.0MiB/s]\u001b[A\n",
            " 32%|###1      | 594M/1.87G [00:11<00:17, 71.8MiB/s]\u001b[A\n",
            " 32%|###2      | 601M/1.87G [00:11<00:17, 73.7MiB/s]\u001b[A\n",
            " 33%|###2      | 609M/1.87G [00:11<00:17, 73.4MiB/s]\u001b[A\n",
            " 33%|###3      | 617M/1.87G [00:11<00:16, 75.3MiB/s]\u001b[A\n",
            " 33%|###3      | 625M/1.87G [00:11<00:16, 75.8MiB/s]\u001b[A\n",
            " 34%|###3      | 632M/1.87G [00:11<00:25, 48.7MiB/s]\u001b[A\n",
            " 34%|###4      | 641M/1.87G [00:12<00:21, 56.5MiB/s]\u001b[A\n",
            " 35%|###4      | 649M/1.87G [00:12<00:19, 63.2MiB/s]\u001b[A\n",
            " 35%|###5      | 658M/1.87G [00:12<00:17, 69.3MiB/s]\u001b[A\n",
            " 36%|###5      | 667M/1.87G [00:12<00:16, 73.6MiB/s]\u001b[A\n",
            " 36%|###6      | 675M/1.87G [00:12<00:16, 74.2MiB/s]\u001b[A\n",
            " 37%|###6      | 683M/1.87G [00:12<00:15, 78.2MiB/s]\u001b[A\n",
            " 37%|###7      | 693M/1.87G [00:12<00:14, 81.8MiB/s]\u001b[A\n",
            " 38%|###7      | 701M/1.87G [00:12<00:14, 81.5MiB/s]\u001b[A\n",
            " 38%|###7      | 709M/1.87G [00:12<00:14, 81.7MiB/s]\u001b[A\n",
            " 38%|###8      | 718M/1.87G [00:12<00:15, 73.7MiB/s]\u001b[A\n",
            " 39%|###8      | 725M/1.87G [00:13<00:15, 71.5MiB/s]\u001b[A\n",
            " 39%|###9      | 733M/1.87G [00:13<00:15, 74.1MiB/s]\u001b[A\n",
            " 40%|###9      | 741M/1.87G [00:13<00:14, 75.4MiB/s]\u001b[A\n",
            " 40%|####      | 749M/1.87G [00:13<00:14, 75.8MiB/s]\u001b[A\n",
            " 40%|####      | 757M/1.87G [00:13<00:15, 72.0MiB/s]\u001b[A\n",
            " 41%|####      | 764M/1.87G [00:13<00:14, 74.0MiB/s]\u001b[A\n",
            " 41%|####1     | 772M/1.87G [00:13<00:14, 74.6MiB/s]\u001b[A\n",
            " 42%|####1     | 780M/1.87G [00:13<00:14, 74.7MiB/s]\u001b[A\n",
            " 42%|####2     | 787M/1.87G [00:13<00:14, 75.5MiB/s]\u001b[A\n",
            " 43%|####2     | 796M/1.87G [00:13<00:13, 77.6MiB/s]\u001b[A\n",
            " 43%|####3     | 803M/1.87G [00:14<00:13, 76.1MiB/s]\u001b[A\n",
            " 43%|####3     | 811M/1.87G [00:14<00:13, 76.4MiB/s]\u001b[A\n",
            " 44%|####3     | 819M/1.87G [00:14<00:13, 75.2MiB/s]\u001b[A\n",
            " 44%|####4     | 826M/1.87G [00:14<00:14, 72.1MiB/s]\u001b[A\n",
            " 45%|####4     | 833M/1.87G [00:14<00:14, 70.7MiB/s]\u001b[A\n",
            " 45%|####5     | 841M/1.87G [00:15<00:33, 31.0MiB/s]\u001b[A\n",
            " 45%|####5     | 847M/1.87G [00:15<00:28, 36.4MiB/s]\u001b[A\n",
            " 46%|####5     | 854M/1.87G [00:15<00:24, 42.1MiB/s]\u001b[A\n",
            " 46%|####6     | 860M/1.87G [00:15<00:22, 45.5MiB/s]\u001b[A\n",
            " 46%|####6     | 867M/1.87G [00:15<00:20, 49.6MiB/s]\u001b[A\n",
            " 47%|####6     | 873M/1.87G [00:15<00:18, 53.4MiB/s]\u001b[A\n",
            " 47%|####7     | 880M/1.87G [00:15<00:17, 56.9MiB/s]\u001b[A\n",
            " 47%|####7     | 887M/1.87G [00:15<00:16, 59.8MiB/s]\u001b[A\n",
            " 48%|####7     | 893M/1.87G [00:15<00:16, 59.3MiB/s]\u001b[A\n",
            " 48%|####8     | 899M/1.87G [00:15<00:15, 60.6MiB/s]\u001b[A\n",
            " 49%|####8     | 906M/1.87G [00:16<00:15, 62.8MiB/s]\u001b[A\n",
            " 49%|####8     | 914M/1.87G [00:16<00:14, 66.3MiB/s]\u001b[A\n",
            " 49%|####9     | 921M/1.87G [00:16<00:13, 67.9MiB/s]\u001b[A\n",
            " 50%|####9     | 928M/1.87G [00:16<00:13, 68.0MiB/s]\u001b[A\n",
            " 50%|#####     | 935M/1.87G [00:16<00:13, 67.4MiB/s]\u001b[A\n",
            " 50%|#####     | 942M/1.87G [00:16<00:13, 68.8MiB/s]\u001b[A\n",
            " 51%|#####     | 949M/1.87G [00:16<00:13, 69.1MiB/s]\u001b[A\n",
            " 51%|#####1    | 956M/1.87G [00:16<00:13, 68.7MiB/s]\u001b[A\n",
            " 52%|#####1    | 963M/1.87G [00:16<00:13, 67.4MiB/s]\u001b[A\n",
            " 52%|#####1    | 971M/1.87G [00:17<00:12, 71.7MiB/s]\u001b[A\n",
            " 52%|#####2    | 979M/1.87G [00:17<00:12, 73.8MiB/s]\u001b[A\n",
            " 53%|#####2    | 987M/1.87G [00:17<00:11, 77.3MiB/s]\u001b[A\n",
            " 53%|#####3    | 996M/1.87G [00:17<00:11, 78.9MiB/s]\u001b[A\n",
            " 54%|#####3    | 1.00G/1.87G [00:17<00:10, 79.1MiB/s]\u001b[A\n",
            " 54%|#####4    | 1.01G/1.87G [00:17<00:10, 80.5MiB/s]\u001b[A\n",
            " 55%|#####4    | 1.02G/1.87G [00:17<00:10, 77.8MiB/s]\u001b[A\n",
            " 55%|#####5    | 1.03G/1.87G [00:17<00:10, 78.4MiB/s]\u001b[A\n",
            " 55%|#####5    | 1.04G/1.87G [00:17<00:10, 79.8MiB/s]\u001b[A\n",
            " 56%|#####5    | 1.05G/1.87G [00:17<00:10, 81.6MiB/s]\u001b[A\n",
            " 56%|#####6    | 1.05G/1.87G [00:18<00:11, 72.6MiB/s]\u001b[A\n",
            " 57%|#####6    | 1.06G/1.87G [00:18<00:11, 70.0MiB/s]\u001b[A\n",
            " 57%|#####7    | 1.07G/1.87G [00:18<00:11, 72.5MiB/s]\u001b[A\n",
            " 58%|#####7    | 1.08G/1.87G [00:18<00:10, 72.8MiB/s]\u001b[A\n",
            " 58%|#####8    | 1.08G/1.87G [00:18<00:10, 74.4MiB/s]\u001b[A\n",
            " 58%|#####8    | 1.09G/1.87G [00:18<00:10, 71.7MiB/s]\u001b[A\n",
            " 59%|#####8    | 1.10G/1.87G [00:18<00:10, 72.7MiB/s]\u001b[A\n",
            " 59%|#####9    | 1.11G/1.87G [00:18<00:10, 74.4MiB/s]\u001b[A\n",
            " 60%|#####9    | 1.12G/1.87G [00:18<00:09, 77.1MiB/s]\u001b[A\n",
            " 60%|######    | 1.12G/1.87G [00:18<00:09, 78.9MiB/s]\u001b[A\n",
            " 61%|######    | 1.13G/1.87G [00:19<00:08, 81.8MiB/s]\u001b[A\n",
            " 61%|######1   | 1.14G/1.87G [00:19<00:08, 84.0MiB/s]\u001b[A\n",
            " 62%|######1   | 1.15G/1.87G [00:19<00:08, 83.6MiB/s]\u001b[A\n",
            " 62%|######1   | 1.16G/1.87G [00:19<00:08, 82.2MiB/s]\u001b[A\n",
            " 62%|######2   | 1.17G/1.87G [00:19<00:08, 82.6MiB/s]\u001b[A\n",
            " 63%|######2   | 1.17G/1.87G [00:19<00:08, 79.4MiB/s]\u001b[A\n",
            " 63%|######3   | 1.18G/1.87G [00:19<00:08, 78.5MiB/s]\u001b[A\n",
            " 64%|######3   | 1.19G/1.87G [00:19<00:09, 73.0MiB/s]\u001b[A\n",
            " 64%|######4   | 1.20G/1.87G [00:19<00:09, 68.4MiB/s]\u001b[A\n",
            " 64%|######4   | 1.20G/1.87G [00:20<00:09, 67.7MiB/s]\u001b[A\n",
            " 65%|######4   | 1.21G/1.87G [00:20<00:10, 60.6MiB/s]\u001b[A\n",
            " 65%|######5   | 1.22G/1.87G [00:20<00:11, 54.6MiB/s]\u001b[A\n",
            " 65%|######5   | 1.22G/1.87G [00:20<00:11, 54.0MiB/s]\u001b[A\n",
            " 66%|######5   | 1.23G/1.87G [00:20<00:11, 53.3MiB/s]\u001b[A\n",
            " 66%|######6   | 1.23G/1.87G [00:20<00:12, 51.6MiB/s]\u001b[A\n",
            " 66%|######6   | 1.24G/1.87G [00:20<00:12, 51.8MiB/s]\u001b[A\n",
            " 67%|######6   | 1.24G/1.87G [00:20<00:12, 51.8MiB/s]\u001b[A\n",
            " 67%|######6   | 1.25G/1.87G [00:20<00:11, 51.6MiB/s]\u001b[A\n",
            " 67%|######7   | 1.26G/1.87G [00:21<00:11, 54.4MiB/s]\u001b[A\n",
            " 68%|######7   | 1.26G/1.87G [00:21<00:11, 55.0MiB/s]\u001b[A\n",
            " 68%|######7   | 1.27G/1.87G [00:21<00:10, 55.5MiB/s]\u001b[A\n",
            " 68%|######8   | 1.27G/1.87G [00:21<00:10, 56.0MiB/s]\u001b[A\n",
            " 68%|######8   | 1.28G/1.87G [00:21<00:10, 54.2MiB/s]\u001b[A\n",
            " 69%|######8   | 1.28G/1.87G [00:21<00:10, 54.3MiB/s]\u001b[A\n",
            " 69%|######9   | 1.29G/1.87G [00:21<00:10, 52.7MiB/s]\u001b[A\n",
            " 69%|######9   | 1.29G/1.87G [00:21<00:13, 43.9MiB/s]\u001b[A\n",
            " 70%|######9   | 1.30G/1.87G [00:21<00:12, 44.0MiB/s]\u001b[A\n",
            " 70%|######9   | 1.30G/1.87G [00:22<00:12, 46.8MiB/s]\u001b[A\n",
            " 70%|#######   | 1.31G/1.87G [00:22<00:11, 49.0MiB/s]\u001b[A\n",
            " 70%|#######   | 1.32G/1.87G [00:22<00:11, 49.9MiB/s]\u001b[A\n",
            " 71%|#######   | 1.32G/1.87G [00:22<00:10, 50.6MiB/s]\u001b[A\n",
            " 71%|#######   | 1.33G/1.87G [00:22<00:10, 50.9MiB/s]\u001b[A\n",
            " 71%|#######1  | 1.33G/1.87G [00:22<00:10, 51.6MiB/s]\u001b[A\n",
            " 72%|#######1  | 1.34G/1.87G [00:22<00:10, 51.9MiB/s]\u001b[A\n",
            " 72%|#######1  | 1.34G/1.87G [00:22<00:10, 51.1MiB/s]\u001b[A\n",
            " 72%|#######2  | 1.35G/1.87G [00:22<00:10, 50.5MiB/s]\u001b[A\n",
            " 72%|#######2  | 1.35G/1.87G [00:22<00:09, 52.0MiB/s]\u001b[A\n",
            " 73%|#######2  | 1.36G/1.87G [00:23<00:09, 52.3MiB/s]\u001b[A\n",
            " 73%|#######2  | 1.36G/1.87G [00:23<00:09, 50.9MiB/s]\u001b[A\n",
            " 73%|#######3  | 1.37G/1.87G [00:23<00:09, 52.2MiB/s]\u001b[A\n",
            " 74%|#######3  | 1.37G/1.87G [00:23<00:09, 53.1MiB/s]\u001b[A\n",
            " 74%|#######3  | 1.38G/1.87G [00:23<00:09, 53.0MiB/s]\u001b[A\n",
            " 74%|#######4  | 1.39G/1.87G [00:23<00:09, 53.5MiB/s]\u001b[A\n",
            " 74%|#######4  | 1.39G/1.87G [00:23<00:09, 52.7MiB/s]\u001b[A\n",
            " 75%|#######4  | 1.40G/1.87G [00:23<00:10, 46.2MiB/s]\u001b[A\n",
            " 75%|#######4  | 1.40G/1.87G [00:24<00:11, 41.5MiB/s]\u001b[A\n",
            " 75%|#######5  | 1.40G/1.87G [00:24<00:11, 41.5MiB/s]\u001b[A\n",
            " 75%|#######5  | 1.41G/1.87G [00:24<00:10, 44.9MiB/s]\u001b[A\n",
            " 76%|#######5  | 1.42G/1.87G [00:24<00:09, 47.3MiB/s]\u001b[A\n",
            " 76%|#######6  | 1.42G/1.87G [00:24<00:09, 48.5MiB/s]\u001b[A\n",
            " 76%|#######6  | 1.43G/1.87G [00:24<00:08, 49.9MiB/s]\u001b[A\n",
            " 77%|#######6  | 1.43G/1.87G [00:24<00:08, 50.1MiB/s]\u001b[A\n",
            " 77%|#######6  | 1.44G/1.87G [00:24<00:08, 48.9MiB/s]\u001b[A\n",
            " 77%|#######7  | 1.44G/1.87G [00:24<00:09, 47.4MiB/s]\u001b[A\n",
            " 77%|#######7  | 1.45G/1.87G [00:24<00:09, 43.9MiB/s]\u001b[A\n",
            " 78%|#######7  | 1.45G/1.87G [00:25<00:09, 44.2MiB/s]\u001b[A\n",
            " 78%|#######7  | 1.46G/1.87G [00:25<00:08, 45.9MiB/s]\u001b[A\n",
            " 78%|#######8  | 1.46G/1.87G [00:25<00:08, 47.2MiB/s]\u001b[A\n",
            " 78%|#######8  | 1.47G/1.87G [00:25<00:08, 47.0MiB/s]\u001b[A\n",
            " 79%|#######8  | 1.47G/1.87G [00:25<00:08, 47.9MiB/s]\u001b[A\n",
            " 79%|#######9  | 1.48G/1.87G [00:25<00:07, 50.7MiB/s]\u001b[A\n",
            " 79%|#######9  | 1.48G/1.87G [00:25<00:06, 58.9MiB/s]\u001b[A\n",
            " 80%|#######9  | 1.49G/1.87G [00:25<00:05, 67.1MiB/s]\u001b[A\n",
            " 80%|########  | 1.50G/1.87G [00:25<00:05, 73.1MiB/s]\u001b[A\n",
            " 81%|########  | 1.51G/1.87G [00:25<00:04, 73.2MiB/s]\u001b[A\n",
            " 81%|########1 | 1.52G/1.87G [00:26<00:04, 76.3MiB/s]\u001b[A\n",
            " 82%|########1 | 1.53G/1.87G [00:26<00:04, 78.9MiB/s]\u001b[A\n",
            " 82%|########2 | 1.53G/1.87G [00:26<00:04, 74.8MiB/s]\u001b[A\n",
            " 82%|########2 | 1.54G/1.87G [00:26<00:04, 66.9MiB/s]\u001b[A\n",
            " 83%|########2 | 1.55G/1.87G [00:26<00:04, 69.8MiB/s]\u001b[A\n",
            " 83%|########3 | 1.56G/1.87G [00:26<00:04, 71.8MiB/s]\u001b[A\n",
            " 84%|########3 | 1.56G/1.87G [00:26<00:04, 73.1MiB/s]\u001b[A\n",
            " 84%|########4 | 1.57G/1.87G [00:26<00:04, 73.9MiB/s]\u001b[A\n",
            " 85%|########4 | 1.58G/1.87G [00:26<00:03, 75.9MiB/s]\u001b[A\n",
            " 85%|########4 | 1.59G/1.87G [00:27<00:03, 75.4MiB/s]\u001b[A\n",
            " 85%|########5 | 1.60G/1.87G [00:27<00:03, 77.1MiB/s]\u001b[A\n",
            " 86%|########5 | 1.60G/1.87G [00:27<00:03, 81.0MiB/s]\u001b[A\n",
            " 86%|########6 | 1.61G/1.87G [00:27<00:03, 82.5MiB/s]\u001b[A\n",
            " 87%|########6 | 1.62G/1.87G [00:27<00:02, 82.7MiB/s]\u001b[A\n",
            " 87%|########7 | 1.63G/1.87G [00:27<00:02, 83.1MiB/s]\u001b[A\n",
            " 88%|########7 | 1.64G/1.87G [00:27<00:02, 82.9MiB/s]\u001b[A\n",
            " 88%|########8 | 1.65G/1.87G [00:27<00:02, 81.3MiB/s]\u001b[A\n",
            " 89%|########8 | 1.65G/1.87G [00:27<00:02, 78.4MiB/s]\u001b[A\n",
            " 89%|########8 | 1.66G/1.87G [00:28<00:10, 20.4MiB/s]\u001b[A\n",
            " 89%|########9 | 1.67G/1.87G [00:29<00:07, 25.5MiB/s]\u001b[A\n",
            " 90%|########9 | 1.68G/1.87G [00:29<00:05, 31.9MiB/s]\u001b[A\n",
            " 90%|######### | 1.68G/1.87G [00:29<00:06, 29.7MiB/s]\u001b[A\n",
            " 91%|######### | 1.69G/1.87G [00:29<00:04, 37.0MiB/s]\u001b[A\n",
            " 91%|#########1| 1.70G/1.87G [00:29<00:03, 44.8MiB/s]\u001b[A\n",
            " 91%|#########1| 1.71G/1.87G [00:29<00:03, 51.5MiB/s]\u001b[A\n",
            " 92%|#########1| 1.72G/1.87G [00:29<00:02, 58.4MiB/s]\u001b[A\n",
            " 92%|#########2| 1.72G/1.87G [00:29<00:02, 63.7MiB/s]\u001b[A\n",
            " 93%|#########2| 1.73G/1.87G [00:29<00:01, 67.8MiB/s]\u001b[A\n",
            " 93%|#########3| 1.74G/1.87G [00:30<00:01, 69.0MiB/s]\u001b[A\n",
            " 94%|#########3| 1.75G/1.87G [00:30<00:01, 71.6MiB/s]\u001b[A\n",
            " 94%|#########3| 1.76G/1.87G [00:30<00:01, 62.7MiB/s]\u001b[A\n",
            " 94%|#########4| 1.76G/1.87G [00:30<00:01, 65.6MiB/s]\u001b[A\n",
            " 95%|#########4| 1.77G/1.87G [00:30<00:01, 68.3MiB/s]\u001b[A\n",
            " 95%|#########5| 1.78G/1.87G [00:30<00:01, 69.3MiB/s]\u001b[A\n",
            " 96%|#########5| 1.79G/1.87G [00:30<00:01, 71.5MiB/s]\u001b[A\n",
            " 96%|#########6| 1.79G/1.87G [00:30<00:01, 72.8MiB/s]\u001b[A\n",
            " 96%|#########6| 1.80G/1.87G [00:30<00:00, 71.8MiB/s]\u001b[A\n",
            " 97%|#########6| 1.81G/1.87G [00:31<00:00, 69.6MiB/s]\u001b[A\n",
            " 97%|#########7| 1.82G/1.87G [00:31<00:00, 71.6MiB/s]\u001b[A\n",
            " 98%|#########7| 1.82G/1.87G [00:31<00:00, 74.3MiB/s]\u001b[A\n",
            " 98%|#########8| 1.83G/1.87G [00:31<00:00, 76.9MiB/s]\u001b[A\n",
            " 99%|#########8| 1.84G/1.87G [00:31<00:00, 78.6MiB/s]\u001b[A\n",
            " 99%|#########8| 1.85G/1.87G [00:31<00:00, 79.9MiB/s]\u001b[A\n",
            " 99%|#########9| 1.86G/1.87G [00:31<00:00, 81.4MiB/s]\u001b[A\n",
            "100%|##########| 1.87G/1.87G [00:32<00:00, 58.1MiB/s]\n",
            "100%|##########| 4.37k/4.37k [00:00<00:00, 10.1MiB/s]\n",
            ">> DVAE weights restored from: /tmp/xtts_ft/run/training/XTTS_v2.0_original_model_files/dvae.pth\n",
            " | > Found 27 files in /tmp/xtts_ft/dataset\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            " > Training Environment:\n",
            " | > Backend: Torch\n",
            " | > Mixed precision: False\n",
            " | > Precision: float32\n",
            " | > Current device: 0\n",
            " | > Num. of GPUs: 1\n",
            " | > Num. of CPUs: 2\n",
            " | > Num. of Torch Threads: 2\n",
            " | > Torch seed: 1\n",
            " | > Torch CUDNN: True\n",
            " | > Torch CUDNN deterministic: False\n",
            " | > Torch CUDNN benchmark: False\n",
            " | > Torch TF32 MatMul: False\n",
            "2024-08-26 04:41:28.824875: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-26 04:41:29.085508: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-26 04:41:29.160500: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-26 04:41:29.587825: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-08-26 04:41:32.043226: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            " > Start Tensorboard: tensorboard --logdir=/tmp/xtts_ft/run/training/GPT_XTTS_FT-August-26-2024_04+41AM-0000000\n",
            "\n",
            " > Model has 518442047 parameters\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/6\u001b[0m\n",
            " --> /tmp/xtts_ft/run/training/GPT_XTTS_FT-August-26-2024_04+41AM-0000000\n",
            " > Sampling by language: dict_keys(['en'])\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2024-08-26 04:41:34) \u001b[0m\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-08-26 04:41:47 -- STEP: 0/14 -- GLOBAL_STEP: 0\u001b[0m\n",
            "     | > loss_text_ce: 0.02275063283741474  (0.02275063283741474)\n",
            "     | > loss_mel_ce: 3.998446226119995  (3.998446226119995)\n",
            "     | > loss: 4.0211968421936035  (4.0211968421936035)\n",
            "     | > grad_norm: 0  (0)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 2.071  (2.0710015296936035)\n",
            "     | > loader_time: 10.274  (10.273964405059814)\n",
            "\n",
            " > Filtering invalid eval samples!!\n",
            " > Total eval samples after filtering: 4\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.08396315574645996 \u001b[0m(+0)\n",
            "     | > avg_loss_text_ce: 0.02102234773337841 \u001b[0m(+0)\n",
            "     | > avg_loss_mel_ce: 3.7265892028808594 \u001b[0m(+0)\n",
            "     | > avg_loss: 3.7476115226745605 \u001b[0m(+0)\n",
            "\n",
            " > BEST MODEL : /tmp/xtts_ft/run/training/GPT_XTTS_FT-August-26-2024_04+41AM-0000000/best_model_14.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 1/6\u001b[0m\n",
            " --> /tmp/xtts_ft/run/training/GPT_XTTS_FT-August-26-2024_04+41AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-08-26 04:43:41) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.09827423095703125 \u001b[0m(+0.014311075210571289)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.020806817337870598 \u001b[0m(-0.0002155303955078125)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 3.523658037185669 \u001b[0m(-0.20293116569519043)\n",
            "     | > avg_loss:\u001b[92m 3.5444648265838623 \u001b[0m(-0.20314669609069824)\n",
            "\n",
            " > BEST MODEL : /tmp/xtts_ft/run/training/GPT_XTTS_FT-August-26-2024_04+41AM-0000000/best_model_28.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 2/6\u001b[0m\n",
            " --> /tmp/xtts_ft/run/training/GPT_XTTS_FT-August-26-2024_04+41AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-08-26 04:45:58) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.1003427505493164 \u001b[0m(+0.0020685195922851562)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.020491601899266243 \u001b[0m(-0.00031521543860435486)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 3.4433493614196777 \u001b[0m(-0.08030867576599121)\n",
            "     | > avg_loss:\u001b[92m 3.463840961456299 \u001b[0m(-0.08062386512756348)\n",
            "\n",
            " > BEST MODEL : /tmp/xtts_ft/run/training/GPT_XTTS_FT-August-26-2024_04+41AM-0000000/best_model_42.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 3/6\u001b[0m\n",
            " --> /tmp/xtts_ft/run/training/GPT_XTTS_FT-August-26-2024_04+41AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-08-26 04:48:11) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2024-08-26 04:48:19 -- STEP: 8/14 -- GLOBAL_STEP: 50\u001b[0m\n",
            "     | > loss_text_ce: 0.023790592327713966  (0.02285286970436573)\n",
            "     | > loss_mel_ce: 3.253131866455078  (3.384260505437851)\n",
            "     | > loss: 3.2769224643707275  (3.407113343477249)\n",
            "     | > grad_norm: 0  (0.0)\n",
            "     | > current_lr: 5e-06 \n",
            "     | > step_time: 0.325  (0.3431321978569031)\n",
            "     | > loader_time: 0.0203  (0.01151186227798462)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.07922029495239258 \u001b[0m(-0.021122455596923828)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.020151330158114433 \u001b[0m(-0.0003402717411518097)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 3.3978328704833984 \u001b[0m(-0.0455164909362793)\n",
            "     | > avg_loss:\u001b[92m 3.4179842472076416 \u001b[0m(-0.04585671424865723)\n",
            "\n",
            " > BEST MODEL : /tmp/xtts_ft/run/training/GPT_XTTS_FT-August-26-2024_04+41AM-0000000/best_model_56.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 4/6\u001b[0m\n",
            " --> /tmp/xtts_ft/run/training/GPT_XTTS_FT-August-26-2024_04+41AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-08-26 04:50:27) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.0951542854309082 \u001b[0m(+0.015933990478515625)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.019776882603764534 \u001b[0m(-0.0003744475543498993)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 3.370410203933716 \u001b[0m(-0.027422666549682617)\n",
            "     | > avg_loss:\u001b[92m 3.3901870250701904 \u001b[0m(-0.027797222137451172)\n",
            "\n",
            " > BEST MODEL : /tmp/xtts_ft/run/training/GPT_XTTS_FT-August-26-2024_04+41AM-0000000/best_model_70.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 5/6\u001b[0m\n",
            " --> /tmp/xtts_ft/run/training/GPT_XTTS_FT-August-26-2024_04+41AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2024-08-26 04:52:30) \u001b[0m\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.07965350151062012 \u001b[0m(-0.015500783920288086)\n",
            "     | > avg_loss_text_ce:\u001b[92m 0.019526490941643715 \u001b[0m(-0.0002503916621208191)\n",
            "     | > avg_loss_mel_ce:\u001b[92m 3.3404979705810547 \u001b[0m(-0.029912233352661133)\n",
            "     | > avg_loss:\u001b[92m 3.3600244522094727 \u001b[0m(-0.030162572860717773)\n",
            "\n",
            " > BEST MODEL : /tmp/xtts_ft/run/training/GPT_XTTS_FT-August-26-2024_04+41AM-0000000/best_model_84.pth\n",
            "Model training done!\n",
            "Loading XTTS model! \n",
            "Model Loaded!\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2194, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/TTS/TTS/demos/xtts_ft_demo/xtts_demo.py\", line 410, in <module>\n",
            "    demo.launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2101, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2198, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/networking.py\", line 70, in close\n",
            "    def close(self):\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 0.0.0.0:5003 <> https://1512a9b05dadae2db3.gradio.live\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers -U\n",
        "\n",
        "!python TTS/TTS/demos/xtts_ft_demo/xtts_demo.py --batch_size 2 --num_epochs 6\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXEBRA_kq23i"
      },
      "source": [
        "### Downloading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBxgdKcvi4kO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "575ce529-e477-4d2e-d881-67956f033b72"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e9725bee-df5a-40f8-8882-fea95ef72b34\", \"dataset.zip\", 12364702)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "!zip -q -r dataset.zip /tmp/xtts_ft/dataset\n",
        "files.download('dataset.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKzoP53Nq_rJ"
      },
      "source": [
        "### Downloading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpfdzHvKaX8M",
        "outputId": "4ec65304-7d09-456a-bb80-405738671156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f6b14405-3341-4763-9bf5-7192cee2077b\", \"config.json\", 4368)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a97fb625-772e-45ec-a22c-1c996715ad7b\", \"vocab.json\", 361219)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a8f53dab-8ded-4baf-8800-1cc600a0f9b3\", \"model.pth\", 1868275926)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "\n",
        "def find_latest_best_model(folder_path):\n",
        "    search_path = os.path.join(folder_path, '**', 'best_model.pth')\n",
        "    files = glob.glob(search_path, recursive=True)\n",
        "    latest_file = max(files, key=os.path.getctime, default=None)\n",
        "    return latest_file\n",
        "\n",
        "model_path = find_latest_best_model(\"/tmp/xtts_ft/run/training/\")\n",
        "checkpoint = torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
        "del checkpoint[\"optimizer\"]\n",
        "for key in list(checkpoint[\"model\"].keys()):\n",
        "    if \"dvae\" in key:\n",
        "        del checkpoint[\"model\"][key]\n",
        "torch.save(checkpoint, \"model.pth\")\n",
        "model_dir = os.path.dirname(model_path)\n",
        "files.download(os.path.join(model_dir, 'config.json'))\n",
        "files.download(os.path.join(model_dir, 'vocab.json'))\n",
        "files.download('model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh9_SusYdRE4"
      },
      "source": [
        "### Copy files to your google drive\n",
        "\n",
        "The two previous cells are a requirement for this step but it can be much faster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piLAaVHSdQs5",
        "outputId": "26c66e7f-f3c3-46cc-969a-5b6e3465de3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/XTTS_ft_colab/dataset.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "drive.mount('/content/drive')\n",
        "!mkdir /content/drive/MyDrive/XTTS_ft_colab\n",
        "shutil.copy(os.path.join(model_dir, 'config.json'), \"/content/drive/MyDrive/XTTS_ft_colab/config.json\")\n",
        "shutil.copy(os.path.join(model_dir, 'vocab.json'), \"/content/drive/MyDrive/XTTS_ft_colab/vocab.json'\")\n",
        "shutil.copy('model.pth', \"/content/drive/MyDrive/XTTS_ft_colab/model.pth\")\n",
        "shutil.copy('dataset.zip', \"/content/drive/MyDrive/XTTS_ft_colab/dataset.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FOpa9hpbEb2n"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "cdWKA_xFqkKq",
        "oXEBRA_kq23i",
        "ZKzoP53Nq_rJ",
        "Eh9_SusYdRE4"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}